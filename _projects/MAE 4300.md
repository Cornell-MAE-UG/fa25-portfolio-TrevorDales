---
layout: project
title: MAE 4300
description: Just a spaceship that I designed
technologies: [Ethical Mindset]
image: /assets/images/ethics.jpeg

---

The Boeing 737 MAX incidents stand as one of the most important engineering ethics case studies of the modern era. While the immediate cause of the two fatal crashes was linked to the Maneuvering Characteristics Augmentation System (MCAS), the deeper ethical issues extend far beyond a single piece of software. The events surrounding the 737 MAX reveal how engineering judgment can be compromised by organizational pressure, market competition, and a gradual erosion of safety-centered decision making. Ultimately, the tragedy highlights the responsibility engineers have not only to design functional systems, but to advocate for safety, transparency, and ethical integrity throughout the entire development process.

At its core, MCAS was created to address a real engineering challenge. The larger engines on the 737 MAX altered the aircraft’s aerodynamics, particularly at high angles of attack, making the plane more prone to pitching upward. Rather than redesigning the airframe or pursuing a clean-sheet aircraft, Boeing opted to implement a software solution that would automatically push the nose down under certain conditions, preserving handling characteristics similar to earlier 737 models. From a purely technical standpoint, this approach was not unreasonable. However, ethical concerns arise when considering how the system was designed and the assumptions that were made about its reliability.

One of the most troubling aspects of MCAS was its reliance on a single angle-of-attack sensor to trigger corrective action. In safety-critical systems, redundancy is a foundational principle. Engineers are trained to assume that sensors can fail, data can be corrupted, and unexpected conditions will occur. Allowing a single faulty sensor to repeatedly command nose-down trim—without sufficient limits or safeguards—represented a failure to fully account for worst-case scenarios. This decision suggests that trade-offs were made that favored cost savings and design simplicity over robust safety margins, conflicting with the ethical obligation engineers have to protect the public from harm.

Equally significant was the lack of transparency surrounding MCAS. The system was not clearly disclosed in pilot training materials or flight manuals, and many pilots were unaware of its existence before the crashes occurred. This omission was largely motivated by Boeing’s desire to market the 737 MAX as a seamless upgrade that required little to no additional pilot training. From an ethical standpoint, this decision is deeply problematic. Engineers have a duty to ensure that those operating their systems are fully informed of how those systems behave, especially when automated functions can override human control. By prioritizing market competitiveness over clear communication, Boeing shifted risk onto pilots who were unprepared to recognize and respond to MCAS failures.

The ethical issues surrounding the 737 MAX also cannot be separated from the organizational culture at Boeing during its development. Investigations and internal communications released after the crashes revealed a company under intense pressure to compete with Airbus and meet aggressive timelines. Engineers reportedly raised concerns about MCAS authority, sensor redundancy, and safety assumptions, yet these concerns were often minimized or overridden. This highlights a critical ethical challenge in engineering practice: the tension between individual professional responsibility and corporate hierarchy. Ethical engineering requires more than technical skill; it demands the willingness to speak up when safety is compromised, even when doing so may carry professional risk.

Importantly, the 737 MAX incidents demonstrate that ethical failures are rarely the result of a single bad actor or decision. Instead, they emerge gradually through small compromises that accumulate over time. Choices that seem manageable in isolation—such as limiting system documentation or accepting reduced redundancy—can collectively create dangerous conditions. Engineers must remain vigilant against this “normalization of deviance,” where increasingly risky decisions become acceptable simply because no immediate consequences occur.

Beyond the immediate engineering failures, the crashes raise broader questions about accountability and trust. The public places enormous trust in engineers, particularly in fields like aerospace where failures can be catastrophic. That trust is not based solely on technical expertise, but on the belief that safety is always the top priority. When economic incentives or organizational pressures undermine that priority, the ethical foundation of the profession is weakened. The aftermath of the 737 MAX crashes—grounded fleets, loss of life, and lasting reputational damage—illustrates the real-world consequences of violating that trust.

In conclusion, the Boeing 737 MAX incidents serve as a powerful reminder that engineering ethics extend far beyond calculations and code. Engineers must consider how their designs interact with human operators, how information is communicated, and how organizational dynamics influence technical decisions. The tragedy underscores the importance of redundancy, transparency, and ethical courage in engineering practice. Above all, it reinforces the idea that protecting public safety is not just a technical requirement, but a moral responsibility that must guide every stage of engineering work.